# This is a Databricks asset bundle definition for ncpdp.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.
bundle:
  name: ncpdp
  uuid: 6b809732-60d7-4af7-b6d5-5bf169857db6

include:
  - resources/*.yml
  - resources/*/*.yml

# Variable declarations. These variables are assigned in the dev/prod targets below.
variables:
  catalog:
    description: The catalog to use
  schema:
    description: The schema to use
  volume:
    description: The name of the volume to use for autoloading files
    default: landing
  volume_sub_path: 
    description: Sub directory in the volume where the NCPDP files will be autoloaded from, if applicable, with a slash to start and no trailing slash. E.g. /dir1/dir2
    default: ""
  ncpdp_file_types: 
    description: The file types that will be loaded into tables as a string of comma separated values.  Each file type should be placed in its respective directory either at the volume level, or in the volume sub path level.  The directories and the values in the string much match.  E.g. ClaimBilling, ClaimRebill, ClaimReversal
    default: ClaimBilling
  event_log_catalog:
    description: The catalog to publish the ETL Pipeline's event log.
  event_log_schema:
    description: The schema to publish the ETL Pipeline's event log. 
  serverless_environment_version: 
    default: "4"
    description: The Serverless Environment version to use with serverless workflows.  
  run_as_user:
    default: "matthew.giglia@databricks.com"
    description: The principal the workflow and pipelines should run as.  
  tags_parentProject: 
    default: mkgs-databricks-demos
    description: The name of the parent project used for tagging deployed resources. 
  tags_project:
    default: rxClaims
    description: The name of the project/subproject used for tagging deployed resources.
  tags_businessUnit: 
    default: "Healthcare and Life Sciences"
    description: The business or accounting unit assigned.  
  tags_RemoveAfter: 
    default: 2026-12-04
    description: Date the resources may be destroyed safely.  Defaults to one year after deployment. 
  tags_developer: 
    default: matthew.giglia@databricks.com
    description: Original developer or developers for Ops contacts
  tags_requestedBy:
    default: Databricks
    description: Team, company or stakeholders that requested the project.  

targets:
  dev:
    # The default target uses 'mode: development' to create a development copy.
    # - Deployed resources get prefixed with '[dev my_user_name]'
    # - Any job schedules and triggers are paused by default.
    # See also https://docs.databricks.com/dev-tools/bundles/deployment-modes.html.
    mode: development
    presets:
      # name_prefix: '[${bundle.target} ${workspace.current_user.short_name}] '
      source_linked_deployment: true
      trigger_pause_status: PAUSED
      jobs_max_concurrent_runs: 1
      pipelines_development: true
      tags:
        parentProject: ${var.tags_parentProject}
        project: ${var.tags_project}
        businessUnit: ${var.tags_businessUnit}
        requestedBy: ${var.tags_requestedBy}
        developer: ${var.tags_developer}
        RemoveAfter: ${var.tags_RemoveAfter}
        env: ${bundle.target}
    default: true
    workspace:
      host: https://fe-vm-mkgs-databricks-demos.cloud.databricks.com/
    variables:
      catalog: ncpdp_dev
      schema: rx_claims
      volume: landing
      volume_sub_path: ""
      ncpdp_file_types: ClaimBilling
      serverless_environment_version: "4"
      event_log_catalog: ${var.catalog}
      event_log_schema: ${resources.schemas.ncpdp_schema.name}

  e2_demo_fe:
    # The default target uses 'mode: development' to create a development copy.
    # - Deployed resources get prefixed with '[dev my_user_name]'
    # - Any job schedules and triggers are paused by default.
    # See also https://docs.databricks.com/dev-tools/bundles/deployment-modes.html.
    mode: development
    presets:
      name_prefix: '[dev ${workspace.current_user.short_name}] '
      source_linked_deployment: true
      trigger_pause_status: PAUSED
      jobs_max_concurrent_runs: 1
      pipelines_development: true
      tags:
        parentProject: ${var.tags_parentProject}
        project: ${var.tags_project}
        businessUnit: ${var.tags_businessUnit}
        requestedBy: ${var.tags_requestedBy}
        developer: ${var.tags_developer}
        RemoveAfter: ${var.tags_RemoveAfter}
        env: ${bundle.target}
    default: true
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com/
    variables:
      catalog: mgiglia
      schema: ncpdp_rx
      volume: landing
      volume_sub_path: ""
      ncpdp_file_types: ClaimBilling
      serverless_environment_version: "4"
      event_log_catalog: ${var.catalog}
      event_log_schema: ${resources.schemas.ncpdp_schema.name}


  free_edition:
    mode: production
    presets:
      # name_prefix: '[${bundle.target} ${workspace.current_user.short_name}] '
      source_linked_deployment: false
      trigger_pause_status: PAUSED
      jobs_max_concurrent_runs: 1
      pipelines_development: true
      tags:
        parentProject: ${var.tags_parentProject}
        project: ${var.tags_project}
        businessUnit: ${var.tags_businessUnit}
        requestedBy: ${var.tags_requestedBy}
        developer: ${var.tags_developer}
        RemoveAfter: ${var.tags_RemoveAfter}
        env: ${bundle.target}
    workspace:
      host: https://dbc-e5684c0a-20fa.cloud.databricks.com
      # We explicitly deploy to /Workspace/Users/${var.run_as_user} to make sure we only have a single copy. 
      # root_path: /Workspace/Users/${var.run_as_user}/.bundle/${bundle.name}/${bundle.target}
      root_path: /Workspace/${bundle.target}/.bundle/${bundle.name}
    variables:
      catalog: prod
      schema: ncpdp_rx
      volume: landing
      volume_sub_path: ""
      ncpdp_file_types: ClaimBilling
      serverless_environment_version: "4"
      event_log_catalog: ${var.catalog}
      event_log_schema: ${resources.schemas.ncpdp_schema.name}
      run_as_user: matthew.giglia@databricks.com
    permissions:
      - user_name: ${var.run_as_user}
        level: CAN_MANAGE
